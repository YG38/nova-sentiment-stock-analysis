{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyst Ratings EDA\n",
    "This notebook performs exploratory data analysis on the raw analyst ratings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set style for plots\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data\n",
    "file_path = '../raw_analyst_ratings (1).csv'\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Display basic information\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print('\\nFirst few rows of the dataset:')\n",
    "display(df.head())\n",
    "\n",
    "print('\\nData types and non-null counts:')\n",
    "display(df.info())\n",
    "\n",
    "print('\\nSummary statistics:')\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print('Missing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Fill or drop based on the column and context\n",
    "# Example: df['column_name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Convert date columns to datetime if needed\n",
    "# Example: df['date_column'] = pd.to_datetime(df['date_column'])\n",
    "\n",
    "# Remove duplicates if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'\nShape after removing duplicates: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic statistics for numerical columns\n",
    "print('Descriptive statistics for numerical columns:')\n",
    "display(df.describe())\n",
    "\n",
    "# Count of unique values in categorical columns\n",
    "print('\\nCount of unique values in categorical columns:')\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    print(f'\\n{column}:')\n",
    "    print(df[column].value_counts().head())\n",
    "    print(f'Total unique values: {df[column].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Assuming there's a date column, adjust the column name as needed\n",
    "# Example with a hypothetical 'date' column\n",
    "if 'date' in df.columns:\n",
    "    # Convert to datetime and set as index\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Resample by day and count\n",
    "    daily_counts = df.resample('D').size()\n",
    "    \n",
    "    # Plot time series\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    daily_counts.plot()\n",
    "    plt.title('Number of Articles Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Articles')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Reset index for further analysis\n",
    "    df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Assuming there's a text column, adjust the column name as needed\n",
    "if 'text' in df.columns:\n",
    "    # Analyze text length\n",
    "    df['text_length'] = df['text'].apply(len)\n",
    "    \n",
    "    # Plot distribution of text lengths\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df['text_length'], bins=50)\n",
    "    plt.title('Distribution of Text Lengths')\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Sentiment Analysis\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    df['sentiment'] = df['text'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "    \n",
    "    # Plot sentiment distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df['sentiment'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Sentiment Scores')\n",
    "    plt.xlabel('Sentiment Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Assuming there's a publisher column, adjust the column name as needed\n",
    "if 'publisher' in df.columns:\n",
    "    # Top publishers by article count\n",
    "    publisher_counts = df['publisher'].value_counts().head(20)\n",
    "    \n",
    "    # Plot top publishers\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(y=publisher_counts.index, x=publisher_counts.values, palette='viridis')\n",
    "    plt.title('Top 20 Publishers by Number of Articles')\n",
    "    plt.xlabel('Number of Articles')\n",
    "    plt.ylabel('Publisher')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select numerical columns for correlation analysis\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "if len(numerical_cols) > 1:  # Need at least 2 numerical columns\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix of Numerical Variables')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Analysis (Customize based on your data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add any additional analysis specific to your dataset\n",
    "# For example:\n    "# - Word frequency analysis\n",
    "# - Topic modeling\n",
    "# - Time series forecasting\n",
    "# - Sentiment over time\n",
    "# - Publisher-specific analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the processed data for further analysis\n",
    "# df.to_csv('../processed_analyst_ratings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
