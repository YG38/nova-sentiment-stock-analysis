{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis of Analyst Ratings\n",
    "\n",
    "## Overview\n",
    "This notebook performs exploratory data analysis on the analyst ratings dataset to understand:\n",
    "1. Basic statistics and data quality\n",
    "2. Text analysis of headlines and summaries\n",
    "3. Time series analysis of publication frequency\n",
    "4. Publisher analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = '../raw_analyst_ratings (1).csv'\n",
    "\n",
    "# Read only the first 100,000 rows for initial analysis\n",
    "df = pd.read_csv(file_path, nrows=100000, parse_dates=['date'], low_memory=False)\n",
    "\n",
    "# Display basic info\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality and Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"\\nData Types and Missing Values:\")\n",
    "print(df.info())\n",
    "\n",
    "# Basic statistics for numerical columns\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe(include='all').T)\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze headline length\n",
    "df['headline_length'] = df['headline'].str.len()\n",
    "\n",
    "# Plot headline length distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['headline_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Headline Lengths')\n",
    "plt.xlabel('Headline Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common words in headlines\n",
    "def get_top_words(text_series, n=20):\n",
    "    words = ' '.join(text_series.dropna()).lower().split()\n",
    "    # Remove common stop words and single characters\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "    return pd.Series(Counter(words)).nlargest(n)\n",
    "\n",
    "top_words = get_top_words(df['headline'])\n",
    "\n",
    "# Plot top words\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_words.values, y=top_words.index, palette='viridis')\n",
    "plt.title('Top 20 Most Common Words in Headlines')\n",
    "plt.xlabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample by day and count articles\n",
    "daily_counts = df.set_index('date').resample('D').size()\n",
    "\n",
    "# Plot publication frequency over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "daily_counts.plot()\n",
    "plt.title('Number of Articles Published Daily')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze publication by day of week\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    
